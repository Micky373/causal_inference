{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and loading the data\n",
    "\n",
    "all_var_df = pd.read_csv('../data/cleaned_data.csv')\n",
    "causal_var_df = pd.read_csv('../data/causal_inference_data.csv')\n",
    "hold_out_df = pd.read_csv('../data/hold_out_data.csv')\n",
    "causal_hold_out = pd.read_csv('../data/causal_hold_out_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the feature and target variables from the above read data\n",
    "\n",
    "X_all = all_var_df.drop([\"diagnosis\"], axis=1)\n",
    "y_all = all_var_df[\"diagnosis\"]\n",
    "X_causal = causal_var_df.drop([\"diagnosis\"], axis=1)\n",
    "y_causal = causal_var_df[\"diagnosis\"]\n",
    "X_hold = hold_out_df.drop([\"diagnosis\"], axis=1)\n",
    "y_hold = hold_out_df[\"diagnosis\"]\n",
    "X_causal_hold = causal_hold_out.drop([\"diagnosis\"], axis=1)\n",
    "y_causal_hold = causal_hold_out[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for the feature extracted dataframe\n",
    "\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
    "    X_all, y_all,test_size=0.2, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for the causal inference dataframe\n",
    "\n",
    "X_train_causal, X_test_causal, y_train_causal, y_test_causal = train_test_split(\n",
    "    X_causal, y_causal,test_size=0.2, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the feature extracted model\n",
    "\n",
    "classifier_all = RandomForestClassifier(n_estimators=100)\n",
    "classifier_all.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the causal inferred model\n",
    "\n",
    "classifier_causal= RandomForestClassifier(n_estimators=100)\n",
    "classifier_causal.fit(X_train_causal, y_train_causal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the feature extracted model\n",
    "\n",
    "y_pred_all = classifier_all.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the causal inferred model\n",
    "\n",
    "y_pred_causal = classifier_causal.predict(X_test_causal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the random forest regressor for the whole variable is : 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "# Finding out the accuracy of the feature extracted model\n",
    "\n",
    "print ('Accuracy Score of the random forest regressor for the whole variable is :',accuracy_score(y_test_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the random forest regressor for the causal inference variable is: 0.9726027397260274\n"
     ]
    }
   ],
   "source": [
    "# Finding out the accuracy of the causal inferred model\n",
    "\n",
    "print ('Accuracy Score of the random forest regressor for the causal inference variable is:',accuracy_score(y_test_causal, y_pred_causal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above results we can see that the causal inference has better accuracy. From this we can see that even after feature selection we can get better accuracy by using causal inference and decreasing the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets see how the models are accurate to the hold_out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicing the hold out data by using the above trained two models\n",
    "\n",
    "y_pred_all_hold = classifier_all.predict(X_hold)\n",
    "y_pred_causal_hold = classifier_causal.predict(X_causal_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the random forest regressor for the causal inference variable is: 0.9380530973451328\n",
      "Accuracy Score of the random forest regressor for the whole variable is: 0.9823008849557522\n"
     ]
    }
   ],
   "source": [
    "# Finding out the accuracy of the above models by using the hold out data\n",
    "\n",
    "print ('Accuracy Score of the random forest regressor for the causal inference variable is:',accuracy_score(y_causal_hold, y_pred_causal_hold))\n",
    "print ('Accuracy Score of the random forest regressor for the whole variable is:',accuracy_score(y_hold, y_pred_all_hold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above metrices we can infer that the causal inference model accuracy for the hold_out data set is slightly less than the whole feature selected variable model accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('causal_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5266d8fbad3a20596ba83ba672acacd04c842eca1bf921e71a4ccdc91cb0ac96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
