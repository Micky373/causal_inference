{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the useful libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the usefull modules from the script folder\n",
    "\n",
    "from scripts import vizualization as viz\n",
    "from scripts import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and reading the data\n",
    "\n",
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unwanted column\n",
    "\n",
    "df.drop('Unnamed: 32', inplace=True, axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing the information about the dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to see the count mean and other useful attributes of the data \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for any missing value\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the raw and column of the data frame\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the unique values in the diagnosis column\n",
    "\n",
    "df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizing the diagnosis column\n",
    "\n",
    "viz.count_plot(df,'diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the data frame that has string attribute\n",
    "\n",
    "encoded_df = df.copy()\n",
    "utils.encoding_data(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlation of all the features\n",
    "\n",
    "utils.corr_matrix(encoded_df,'Correlation matrix of all the dataset','general_correlation.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlation of the highly correlated columns\n",
    "\n",
    "columns_for_analysis = utils.find_high_corr(encoded_df)\n",
    "utils.corr_matrix(encoded_df[columns_for_analysis],'Correlation matrix for highly related features','higher_correlation.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with bivariate analysis given useful columns and vizualizing\n",
    "\n",
    "mean_col = ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "\n",
    "viz.plot_ditribution(df,mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\", \"concavity\", \"concave points\", \"symmetry\", \"fractal_dimension\"]\n",
    "fields = [\"mean\", \"se\", \"worst\"]\n",
    "viz.feature_vs_target(df,columns,fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualzing for an outlier\n",
    "\n",
    "columns = ['texture_mean', 'radius_mean']\n",
    "viz.plot_outlier(df,columns,'Outliers in texture_mean and radius_mean \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the outlier\n",
    "\n",
    "df_clean = utils.fix_outlier(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the dataframe and check if there is any outlier\n",
    "\n",
    "viz.plot_outlier(df_clean,columns, 'Outliers fixed in texture_mean and radius_mean \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the dataframe for better model accuracy\n",
    "\n",
    "scaled_df = utils.scaler(encoded_df)\n",
    "scaled_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unwanted id column\n",
    "\n",
    "new_df = scaled_df.drop(['id'],axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features and target variable\n",
    "\n",
    "X = new_df.drop([\"diagnosis\"], axis=1)\n",
    "y = new_df[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test splitting\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,test_size=0.2, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model defination\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the model\n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the model accuracy\n",
    "\n",
    "print ('Accuracy Score of the random forest regressor is :',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the feature importance\n",
    "\n",
    "importances = classifier.feature_importances_\n",
    "labels = X.columns\n",
    "feature_df = pd.DataFrame(list(zip(labels, importances)), columns=[\"feature\", \"importance\"])\n",
    "feature_df = feature_df.sort_values(by='importance', ascending=False, )\n",
    "significant_features_df = feature_df.head(10)\n",
    "significant_features_df.shape\n",
    "significant_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizing the top 10 features \n",
    "\n",
    "viz.plot_bar(significant_features_df,'Top 10 features', 'top_10_features.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After analysis and feature importance these features were considered as most important for the model\n",
    "\n",
    "significant_feature_columns = ['concave points_mean','radius_worst','concave points_worst','perimeter_worst','area_mean','perimeter_mean','radius_mean']\n",
    "final_df = new_df[significant_feature_columns]\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data for better modeling \n",
    "\n",
    "norm = Normalizer()\n",
    "clean_df = pd.DataFrame(norm.fit_transform(final_df), columns=significant_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the diagnosis column after normalizing the dataset\n",
    "\n",
    "clean_df['diagnosis'] = new_df['diagnosis']\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the csv file from the processed dataframe\n",
    "\n",
    "clean_df.to_csv('../data/cleaned_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('causal_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5266d8fbad3a20596ba83ba672acacd04c842eca1bf921e71a4ccdc91cb0ac96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
